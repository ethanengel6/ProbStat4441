---
title: "Mann Whitney U-test"
author: "C. Durso"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggpubr)
```

## The Data

The data are results of timing runs for a recursive implementation of Merge Sort applied to sorted data and permuted data. The data were generated by the author. Restrict to time of type "user"

```{r}
load("sorted_vs_permuted_data.RData")
sorted.vs.permuted<-filter(sorted.vs.permuted,time.type=="user")
```

The data have the results of multiple runs in separate columns. Having a single column for each timing type will be more convenient. Reshape the data to accomplish this using the "gather" function. This is called "going from wide to long". The column names become values of the "key" variable. The entries from the columns become entries in the "value" column. The columns specified at the end are the ones gathered in this way.

```{r}
dat<-gather(sorted.vs.permuted,key="run",value="time",X1:X15)
dat<-arrange(dat,array.type)
dat%>%group_by(array.type)%>%summarize(mean=mean(time))
```

By the way, "spread" takes data from long to wide.

### Non-Normality
```{r}
ggqqplot(dat$time[dat$array.type=="permuted"])
ggqqplot(dat$time[dat$array.type=="sorted"])
```



## Wilcoxon Rank Sum Test
### Two sample version

The 2-sample Wilcoxon Rank Sum Test, also known as the Mann-Whitney U-test, applies to the situation of two independent samples $X$ an $Y$. The null hypothesis is that if $X_i$ is a sample from $X$ and $Y_j$ is a sample from $Y$, then $P\left(X_i<Y_j\right)+\frac{1}{2}P\left(X_i=Y_j\right)=0.5$. If the two distributions have the same shape and only differ possibly by a shift, rejecting the null hypothesis means rejecting the hypothesis that the shift is zero. The test statistic is the number of pairs $(i,j)$ for which $P\left(x_i<y_j\right)$ plus half the number of pairs $(i,j)$ for which $P\left(x_i=y_j\right)$

### Check shift hypothesis

Check that the samples are consistent with populations that differ by an additive shift.

```{r}
qplot(dat$time[dat$array.type=="permuted"],binwidth=.1)
qplot(dat$time[dat$array.type=="sorted"],binwidth=.1)

```



```{r}
dat$rank<-rank(dat$time)
wilcox_vals<-summarize(group_by(dat,array.type),count=n(),rank_sum=sum(rank))
wilcox_vals
np<-wilcox_vals$count[1]
(w<-wilcox_vals$rank_sum[1]-np*(np+1)/2)
```

This is the W from wilcox.test. 

```{r}
(w.test<-wilcox.test(time~array.type, data=dat))
```



For intuition, let's estimate the p-value by comparing the test statistic for the data to multiple values of the test statistic under the model that the all group assigments of the ranks are equally likely. Model this by drawing repeated samples of size equal to the number of times for the permuted array from the ranks represented in the data and computing the Wilcoxon statistic for these ranks.
This model is consistent with $P\left(X_i<Y_j\right)+\frac{1}{2}P\left(X_i=Y_j\right)=0.5$ .

```{r}
pairs<-np*(np+1)/2
set.seed(09876567)
w<-replicate(5000,sum(sample(dat$rank,np))-pairs)
quantile(w,c(.025,.5,.975)) # the test statistic is on the low side.
2*mean(w<=w.test$statistic)

```
## Conclusion

These data are consistent with the times for the sorted array having the same mean as the times for the permuted array.

