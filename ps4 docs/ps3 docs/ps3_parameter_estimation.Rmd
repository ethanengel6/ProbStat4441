---
title: "Problem Set 3"
author: "C. Durso"
output:
  word_document: default
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
```

## Introduction

Please complete the following tasks regarding the data in R. Please generate a solution document in R markdown and upload the .Rmd document and a rendered  .doc, .docx, or .pdf document.  Your work should be based  on the data's being in the same folder as the .Rmd file. Please turn in your work on Canvas. Your solution document should have your answers to the questions and should display the requested plots.

These questions were rendered in R markdown through RStudio (<https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf>, <http://rmarkdown.rstudio.com> ).

## Question 1

(10 points)

Create 10,000 samples of size 10 from the standard Normal distribution and calculate the maximum likelihood values of $\mu$ and $\sigma^2$ for each. Compute the mean of the $\mu$s and the mean of the $\sigma^2$s. Does the maximum likelihood estimate of $\mu$ seem have produce values with the mean equal the true value in the long run? (You may repeat the experiment to help answer this question.) Does the maximum likelihood estimate of $\sigma^2$ seem have produce values with the mean equal the true value in the long run? (Try comparing with the adjusted estimates produced by dividing the sum of the squared differences by 9 instead of 10.)

The maximum likelihood estimate(0.03794131) for $\mu$  is reasonably close to zero, which we would expect.  The maximum likelihood estimates for $\sigma^2$ are 0.9549484, when we use n-1 as the denominator, and 0.8594536 when we divide by n.  The former is closer to 1, which is the value we expect.  Presumably, this is why the R language uses a denominator of n to compute its variance.

```{r}
set.seed(45678)
mat<-matrix(rnorm(20*10),ncol=10)
mat
m <- rowMeans(mat)
mean(m)

sampVariance <- function(x){
  m <- mean(x)
  return(sum((x-m)^2)/(length(x)-1))
} 

sV <- (apply(mat,1,sampVariance))
mean(sV)

popVariance <- function(x){
  m <- mean(x)
  return(sum((x-m)^2)/(length(x)))
} 

pV <- (apply(mat,1,popVariance))
mean(pV)

mean(apply(mat,1,var))
```
## Question 2

(10 points)

The exponential distributions are a one parameter family of continuous distributions, $Exp(\lambda)$. Given $\lambda$, the sample space is $[0,\infty)$ and the probability density function is $f(x)=\lambda\exp(-\lambda x)$. Thus if $x_1...x_n$ are $n$ independent draws from an exponential distribution with parameter $\lambda$, the likelihood function of this sample is $\prod_{i=1}^{n}\lambda\exp(-\lambda x_{i})$. Please derive the maximum likelihood value of $\lambda$ as a function of $x_1...x_n$. That is, given $x_1...x_n$, what value of $\lambda$ maximizes $\prod_{i=1}^{n}\lambda\exp(-\lambda x_{i})$?


$\prod_{i=1}^{n}\lambda\exp(-\lambda x_{i})$

First we take a (natural) log of the distribution.  Then it can be dealt with as a sum, rather than a product, which will be easier to differentiate.

$\log \prod_{i=1}^{n}\lambda\exp(-\lambda x_{i})=\sum_{i=1}^{n}log\lambda\exp(-\lambda x_{i})$

$=log\lambda\exp(-\lambda x_{1})+log\lambda\exp(-\lambda x_{2})+. . .log\lambda\exp(-\lambda x_{n})$

$=log\lambda+log(exp(-\lambda x_{1}))+...log\lambda+log(exp(-\lambda x_{n}))$

$=nlog\lambda+log(exp(-\lambda x_{1}))+log(exp(-\lambda x_{2}))+...log(exp(-\lambda x_{n}))$
$=nlog\lambda-\lambda x_{1}-\lambda x_{2}-\lambda x_{3}. . .-\lambda x_{n}$
$=nlog\lambda-\lambda(\sum_{i=1}^{n})$

Now taking the derivative:
$\frac{d}{d\lambda}(nlog\lambda-\lambda(\sum_{i=1}^{n}))=\frac{n}{\lambda}-\sum_{i=1}^{n}=0$
$\frac{n}{\lambda}=\sum_{i=1}^{n}$
$\lambda=\frac{n}{\sum_{i=1}^{n}}=\frac{1}{\bar{x}}$









## Question 3

### 3.a.

The value of the R function "mean" applied to a vector $\mathbf{v}=(v_1,v_2,...v_n)$ is the arithmentic mean of the vector: $\bar{v}=\frac{1}{n}\sum_{i=1}^nv_i$. The value of the R function "var" applied to the vector $\mathbf{v}$ equals $\frac{1}{n-1}\sum_{i=1}^n(v_i-\bar{v})^2$, a measure of how much the values differ from the mean.
For $\lambda\in\{4,25,100\}$, create samples of size 100,000 from the Poisson distribution with parameter $\lambda$ and the Normal distribution with mean equal to $\lambda$ and sd equal to $\sqrt{\lambda}$. Please compare the values of "mean", "var", "max", and "min" for the Poisson and the Normal samples corresponding to each $\lambda$.(5 points)

When a normal distribution has the parameters: mean=lambda and standard deviation=sqrt(lambda), it approximates a Poisson distribution with parameter lambda, and vice-versa.  The means and standard deviations are similar in all three cases.  The minimums and maximums seem to get even more similar as lambda values increase.  

```{r}
a <- rpois(100000,4)
mean(a); var(a);max(a);min(a)
b <- rnorm(100000,mean=4,sd=2)
mean(b); var(b);max(b);min(b)

c <- rpois(100000,25)
mean(c); var(c);max(c);min(c)
d <- rnorm(100000,mean=25,sd=5)
mean(d); var(d);max(d);min(d)

e <- rpois(100000,100)
mean(e); var(e);max(e);min(e)
f <- rnorm(100000,mean=100,sd=10)
mean(f); var(f);max(f);min(f)

```

### 3.b. 

For the values of $\lambda$ and for integers $x$ with the lower bound of 0 and the upper bounds of 15, 60, and 150, respectively, provide visualizations comparing the probability of an outcome equal to $x$ under $Poisson(\lambda)$ and a value in $(x-.5,x+.5)$ under the Normal distribution with $\mu=\lambda$ and $\sigma^2=\lambda$. Also, for each $\lambda$, give the sum of the absolute differences of the two probabilities for all the values of $x$ assessed. (5 poinhts)

```{r}
xValLamb15 <- c(0:15)
Poisson15 <- c(dpois(0:15,15))
Norm15 <- c(pnorm(q = xValLamb15 + 0.5, mean =15, sd=15^0.5) - pnorm(q = xValLamb15-0.5, mean =15,sd=15^.5))
Diff1 <- Poisson15-Norm15
data.frame(xValLamb15,Poisson15,Norm15,Diff1)
sum(abs(Diff1))

xValLamb60 <- c(0:60)
Poisson60 <- c(dpois(0:60,60))
Norm60 <- c(pnorm(q = xValLamb60 + 0.5, mean =60, sd=60^0.5) - pnorm(q = xValLamb60-0.5, mean =60,sd=60^.5))
Diff2 <- Poisson60-Norm60
data.frame(xValLamb60,Poisson60,Norm60,Diff2)
sum(abs(Diff2))

xValLamb150 <- c(0:150)
Poisson150 <- c(dpois(0:150,150))
Norm150 <- c(pnorm(q = xValLamb150 + 0.5, mean =150, sd=150^0.5) - pnorm(q = xValLamb150-0.5, mean =150,sd=150^.5))
Diff3 <- c(Poisson150-Norm150)
data.frame(xValLamb150,Poisson150,Norm150,Diff3)
sum(abs(Diff3))
```



## Question 4

Please supply the missing code where indicated.

The data sets in these questions were downloaded 1/17/2020 from https://ourworldindata.org/ 

The code chunks below read in a data frame of world populations and a data frame of world population densities. 

```{r}
dat.pop<-read.csv("population.csv",stringsAsFactors = FALSE)
dat.den<-
  read.csv("population-density.csv",stringsAsFactors = FALSE)
names(dat.den)[4]<-"density"
```

 Write code to restrict both data frames to cases in which the value of "Year" is 2000 and the value of "Code" is not the empty string, "", or the value for the whole world,"OWID_WRL". (2 points)

```{r} 
dat2000 <- (dat.pop[dat.pop$Year==2000 & dat.pop$Code!="",])
dat2000
den2000 <- dat.den[dat.den$Year==2000 & dat.den$Code!="",]
den2000

```

Merge the data sets.

```{r}
dat.both<-inner_join(dat2000,den2000,by="Code")
# check: This should equal 1 if the restriction above is correct.
mean(dat.both$Entity.x==dat.both$Entity.y)
dat.both

```



Write code to find the indices in "dat.both" at which the population takes on its minimum or maximum value and at which the density takes on its minimum or maximum value. Store the resulting indices in a vector named "inds". Create a data frame "dat.text" from dat.both that includes only the rows containing these extremes. (3 points)

```{r}
min(dat.both[,4])
max(dat.both[,4])
min(dat.both[,7])
max(dat.both[,7])
inds <- c(which.min(dat.both[,4]),which.max(dat.both[,4]),which.min(dat.both[,7]),which.max(dat.both[,7]))

dat.txt <- dat.both[inds,]
dat.txt
```


#Use "ggplot" to create a point plot of the log of population (on the x-axis) versus the log of density. Store the plot in the variable g. Display the plot. (2 points)

```{r}
dat.both$logpop <-  log(dat.both[,4])
dat.both$logden <- log(dat.both[,7])
dat.both
 
dat.txt <- dat.both[inds,]
dat.txt

g <- ggplot(dat.both, aes(x = logpop, y = logden, label='Entity.x')) + geom_point()
g
```




#The following, when uncommented, should give the previous plot with the names of the entities having extreme population or extreme density, assuming that the result of the "transmute" call was stored back in "dat.both".


```{r}

 g2 <- g + geom_text(data=dat.txt,label=dat.txt$Entity.x)
g2
```

Please add the least squares best fit line with "pop.log" as the $x$-value and "den.log" as the $y$-value in $\mathbf{y}=m\mathbf{x}+b$. Also plot the line minimizing the squared error $\sum\left(x_i-(ly_i+c))^2\right)$ again with "pop.log" as the $x$-value and "den.log" as the $y$-value in such a way that the points $(x,y)$ on the line are related by $x=ly+c$. That is, if $f$ is the function giving "pop.log" as an affine function of "den.log", minimizing the square error  $\sum\left(x_i-(ly_i+c))^2\right)$, plot the inverse function $f^{-1}$. (5 points)

```{r}
mean(logpop)
mean(logden)
delty <- 1/215*sum(logpop*logden-mean(logpop)*mean(logden))
deltx <- 1/215*sum(logpop*logpop-(mean(logpop)^2))
slope <- delty/deltx
slope
#slopeinv <- -deltx/delty
#slopeinv
yint <- (mean(logden)-slope*mean(logpop))
yint

fun.1 <- function(x)(slope*x+yint)
fun.2<- function(x)((x-yint)/slope)
g3 <- g2 +geom_smooth(method=lm,se=FALSE)
g3
g4<- g2+ stat_function(fun=fun.1)+xlim(8,24)
g4
ginv <- ggplot(dat.both, aes(x = logden, y = logpop, label='Entity.x'))+geom_point()+ geom_text(data=dat.txt,label=dat.txt$Entity.x)+stat_function(fun=fun.2)+xlim(0,11)
ginv





```


### Question 5

In some cases, any theoretically useful line through paired data points $\{(x_1,y_1),(x_2,y_2),...(x_n,y_n)\}$ can be assumed to be of the form $y=mx$ with the $y$-intercept equal to 0. For example, let $x$ be the "percent remaining" reading on a battery and let $y$ be the time to reach "percent remaining=0" under some regimen for discharging the battery. Derive the formula for $m$ for the least squares best fit line for this model. (5 points)

Since b=0, the sum of the squares of the differences is $\sum(y_i-mx_i)^2$

Differentiating with respect to m yields: $\frac{d}{dm}\sum(y_i-mx_i)^2=-2\sum(y_i-mx_i)x_i$
We set=0 to find the value of m which minimizes:$-2\sum(y_i-mx_i)x_i=0$
$\sum(y_ix_i-mx_i^2)=0$
$\sum(y_ix_i)=m\sum(x_i^2)$
$m=\frac{\sum(y_ix_i)}{\sum(x_i^2)}$


